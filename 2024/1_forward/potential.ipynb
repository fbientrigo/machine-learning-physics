{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Potentials Naive approach\n",
    "Potential for $i$ sample is as $V_{i}^k$ where $k$ corresponds to an index as the $x$ dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with simple harmonic oscillator\n",
    "M=50\n",
    "x = np.linspace(-1,1,M)\n",
    "V_1 = x**2\n",
    "V_1 = np.reshape(V_1, (1, -1))\n",
    "\n",
    "# eignvalues teoricos\n",
    "E = np.array([k for k in range(M)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional API\n",
    "inputV = layers.Input(shape=V_1[0].shape)\n",
    "hidden1 = layers.Dense(300, activation='sigmoid')(inputV)\n",
    "hidden2 = layers.Dense(100, activation='sigmoid')(hidden1)\n",
    "output = layers.Dense(M, activation='sigmoid')(hidden2)\n",
    "\n",
    "# construccion\n",
    "model = tf.keras.Model(inputs=[inputV], outputs=[output])\n",
    "\n",
    "model.compile(\n",
    "    loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63209563, 0.64861995, 0.6449438 , 0.51514804, 0.64623106,\n",
       "        0.59589785, 0.16342705, 0.26058578, 0.5420518 , 0.54435766,\n",
       "        0.6463727 , 0.8010331 , 0.340649  , 0.24358405, 0.3304996 ,\n",
       "        0.44612423, 0.39727533, 0.5720871 , 0.3787265 , 0.5631058 ,\n",
       "        0.49482277, 0.5298165 , 0.694265  , 0.6526648 , 0.47183004,\n",
       "        0.38478193, 0.5552852 , 0.32851297, 0.37436116, 0.2826595 ,\n",
       "        0.65941954, 0.29386774, 0.35547394, 0.5039998 , 0.15552554,\n",
       "        0.3047922 , 0.44886726, 0.21260373, 0.6638535 , 0.2557885 ,\n",
       "        0.588617  , 0.4916435 , 0.46816558, 0.4549424 , 0.31923616,\n",
       "        0.34102538, 0.7851062 , 0.62377304, 0.48558733, 0.30104885]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(V_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN ODE\n",
    "As one option, using activation funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((1,)),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 1)\n",
    "])\n",
    "\n",
    "NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_system(t, net):\n",
    "    t = t.reshape(-1,1)\n",
    "    t = tf.constant(t, dtype = tf.float32)\n",
    "    t_0 = tf.zeros((1,1))\n",
    "    one = tf.ones((1,1))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(t)\n",
    "\n",
    "        u = net(t)\n",
    "        u_t = tape.gradient(u, t)\n",
    "\n",
    "    ode_loss = u_t - tf.math.cos(2*np.pi*t)\n",
    "    IC_loss = net(t_0) - one\n",
    "\n",
    "    square_loss = tf.square(ode_loss) + tf.square(IC_loss)\n",
    "    total_loss = tf.reduce_mean(square_loss)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential to predict the generating function\n",
    "$$\n",
    "V_{ijk} \\rightarrow \\text{CNN} \\rightarrow \\Lambda(z)\n",
    "$$\n",
    "where $z$ is an auxiliar input, that we can take derivtives with respect to, for extraction of eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
