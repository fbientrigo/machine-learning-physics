@article{adlerSolvingIllposedInverse2017,
  title = {Solving Ill-Posed Inverse Problems Using Iterative Deep Neural Networks},
  author = {Adler, Jonas and {\"O}ktem, Ozan},
  year = {2017},
  month = dec,
  journal = {Inverse Problems},
  volume = {33},
  number = {12},
  eprint = {1704.04058},
  primaryclass = {cs, math},
  pages = {124007},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/1361-6420/aa9581},
  urldate = {2024-03-07},
  abstract = {We propose a partially learned approach for the solution of ill posed inverse problems with not necessarily linear forward operators. The method builds on ideas from classical regularization theory and recent advances in deep learning to perform learning while making use of prior information about the inverse problem encoded in the forward operator, noise model and a regularizing functional. The method results in a gradient-like iterative scheme, where the "gradient" component is learned using a convolutional network that includes the gradients of the data discrepancy and regularizer as input in each iteration. We present results of such a partially learned gradient scheme on a non-linear tomographic inversion problem with simulated data from both the Sheep-Logan phantom as well as a head CT. The outcome is compared against FBP and TV reconstruction and the proposed method provides a 5.4 dB PSNR improvement over the TV reconstruction while being significantly faster, giving reconstructions of 512 x 512 volumes in about 0.4 seconds using a single GPU.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Mathematics - Functional Analysis,Mathematics - Numerical Analysis,Mathematics - Optimization and Control},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\2LPT37FF\\Adler and Öktem - 2017 - Solving ill-posed inverse problems using iterative.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\HQNGYIY4\\1704.html}
}

@article{aktosunUniquenessInverseProblem2011,
  title = {The Uniqueness in the Inverse Problem for Transmission Eigenvalues for the Spherically-Symmetric Variable-Speed Wave Equation},
  author = {Aktosun, Tuncay and Gintides, Drossos and Papanicolaou, Vassilis G.},
  year = {2011},
  month = nov,
  journal = {Inverse Problems},
  volume = {27},
  number = {11},
  eprint = {1106.2843},
  primaryclass = {math-ph},
  pages = {115004},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/0266-5611/27/11/115004},
  urldate = {2024-03-07},
  abstract = {The recovery of a spherically-symmetric wave speed \$v\$ is considered in a bounded spherical region of radius \$b\$ from the set of the corresponding transmission eigenvalues for which the corresponding eigenfunctions are also spherically symmetric. If the integral of \$1/v\$ on the interval \$[0,b]\$ is less than \$b,\$ assuming that there exists at least one \$v\$ corresponding to the data, it is shown that \$v\$ is uniquely determined by the data consisting of such transmission eigenvalues and their "multiplicities," where the "multiplicity" is defined as the multiplicity of the transmission eigenvalue as a zero of a key quantity. When that integral is equal to \$b,\$ the unique recovery is obtained when the data contains one additional piece of information. Some similar results are presented for the unique determination of the potential from the transmission eigenvalues with "multiplicities" for a related Schr{\textbackslash}"odinger equation.},
  archiveprefix = {arxiv},
  keywords = {34B07 34B24 47E05,Mathematical Physics},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\Y3Z7Q2P2\\Aktosun et al. - 2011 - The uniqueness in the inverse problem for transmis.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\XF2MPMN7\\1106.html}
}

@article{arridgeSolvingInverseProblems2019,
  title = {Solving Inverse Problems Using Data-Driven Models},
  author = {Arridge, Simon and Maass, Peter and {\"O}ktem, Ozan and Sch{\"o}nlieb, Carola-Bibiane},
  year = {2019},
  month = may,
  journal = {Acta Numerica},
  volume = {28},
  pages = {1--174},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492919000059},
  urldate = {2024-03-07},
  abstract = {Recent research in inverse problems seeks to develop a mathematically coherent foundation for combining data-driven models, and in particular those based on deep learning, with domain-specific knowledge contained in physical--analytical models. The focus is on solving ill-posed inverse problems that are at the core of many challenging applications in the natural sciences, medicine and life sciences, as well as in engineering and industrial applications. This survey paper aims to give an account of some of the main contributions in data-driven inverse problems.},
  langid = {english},
  file = {C:\Users\fbien.DESKTOP-6FMEAR7\Zotero\storage\2EZLF84E\Arridge et al. - 2019 - Solving inverse problems using data-driven models.pdf}
}

@misc{canfieldLaplaceMethodEnergy2022,
  title = {The {{Laplace}} Method for Energy Eigenvalue Problems in Quantum Mechanics},
  author = {Canfield, Jeremy and Galler, Anna and Freericks, James K.},
  year = {2022},
  month = aug,
  number = {arXiv:2208.07433},
  eprint = {2208.07433},
  primaryclass = {physics, physics:quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.07433},
  urldate = {2024-03-07},
  abstract = {Quantum mechanics has about a dozen exactly solvable potentials. Normally, the time-independent Schroedinger equation for them is solved by using a generalized series solution for the bound states (using the Froebenius method) and then an analytic continuation for the continuum states (if present). In this work, we present an alternative way to solve these problems, based on the Laplace method. This technique uses a similar procedure for the bound states and for the continuum states. It was originally used by Schroedinger when he solved for the wavefunctions of hydrogen. Dirac advocated using this method too. We discuss why it is a powerful approach for graduate students to learn and describe how it can be employed to solve all problems whose wavefunctions are represented in terms of confluent hypergeometric functions.},
  archiveprefix = {arxiv},
  keywords = {Physics - Physics Education,Quantum Physics},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\IR9CDGQR\\Canfield et al. - 2022 - The Laplace method for energy eigenvalue problems .pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\9LPHP87F\\2208.html}
}

@book{coltonInverseAcousticElectromagnetic2013,
  title = {Inverse {{Acoustic}} and {{Electromagnetic Scattering Theory}}},
  author = {Colton, David and Kress, Rainer},
  year = {2013},
  series = {Applied {{Mathematical Sciences}}},
  volume = {93},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-4942-3},
  urldate = {2024-03-07},
  isbn = {978-1-4614-4941-6 978-1-4614-4942-3},
  langid = {english},
  keywords = {acoustic waves,electromagnetic wave,inverse scattering,partial differential equations},
  file = {C:\Users\fbien.DESKTOP-6FMEAR7\Zotero\storage\63CVL65P\Colton and Kress - 2013 - Inverse Acoustic and Electromagnetic Scattering Th.pdf}
}

@article{freilingInverseSturmLiouville2001,
  title = {Inverse {{Sturm}}--{{Liouville Problems}} and {{Their Applications}}},
  author = {Freiling, Gerhard and Yurko, Vjacheslav},
  year = {2001},
  month = jan,
  abstract = {This book presents the main results and methods on inverse spectral problems for Sturm-Liouville differential operators and their applications. Inverse problems of spectral analysis consist in recovering operators from their spectral characteristics. Such problems often appear in mathematics, mechanics, physics, electronics, geophysics, meteorology and other branches of natural sciences. Inverse problems also play an important role in solving nonlinear evolution equations in mathematical physics. Interest in this subject has been increasing permanently because of the appearance of new important applications, and nowadays the inverse problem theory develops intensively all over the world. The greatest success in spectral theory in general, and in particular in inverse spectral problems has been achieved for the Sturm-Liouville operator {$\ell$}y := -y{$\prime\prime$} + q(x)y, (1) which also is called the one-dimensional Schr{\textasciidieresis}odinger operator. The first studies on the spectral theory of such operators were performed by D. Bernoulli, J. d`Alembert, L. Euler, J. Liouville and Ch. Sturm in connection with the solution of the equation describing the vibration of a string. An intensive development of the spectral theory for various classes of differential and integral operators and for operators in abstract spaces took place in the XX-th century. Deep ideas here are due to G. Birkhoff, D. Hilbert, J. von Neumann, V. Steklov, M. Stone, H. Weyl and many other mathematicians. The main results on inverse spectral problems appear in the second half of the XX-th century. We mention here the works by R. Beals, G. Borg, L.D. Faddeev, M.G. Gasymov, I.M. Gelfand, B.M. Levitan, I.G. Khachatryan, M.G. Krein, N. Levinson, Z.L. Leibenson, V.A. Marchenko, L.A. Sakhnovich, E. Trubowitz, V.A. Yurko and others (see Section 1.9 for details). An important role in the inverse spectral theory for the Sturm-Liouville operator was played by the transformation operator method. But this method turned out to be unsuitable for many important classes of inverse problems being more complicated than the Sturm-Liouville operator. At present time other effective methods for solving inverse spectral problems have been created. Among them we point out the method of spectral mappings connected with ideas of the contour integral method. This method seems to be perspective for inverse spectral problems. The created methods allowed to solve a number of important problems in various branches of natural sciences. 2 In recent years there appeared new areas for applications of inverse spectral problems. We mention a remarkable method for solving some nonlinear evolution equations of mathematical physics connected with the use of inverse spectral problems. Another important class of inverse problems, which often appear in applications, is the inverse problem of recovering differential equations from incomplete spectral information when only a part of the spectral information is available for measurement. Many applications are connected with inverse problems for differential equations having singularities and turning points, for higher-order differential operators, for differential operators with delay or other types of ''aftereffect''. The main goals of this book are as follows: {$\bullet$} To present a fairly elementary and complete introduction to the inverse problem theory for ordinary differential equations which is suitable for the ''first reading'' and accessible not only to mathematicians but also to physicists, engineers and students. Note that the book requires knowledge only of classical analysis and the theory of ordinary linear differential equations. {$\bullet$} To describe the main ideas and methods in the inverse problem theory using the Sturm- Liouville operator as a model. Up to now many of these ideas, in particular those which appeared in recent years, are presented in journals only. It is very important that the methods, provided in this book, can be used (and have been already used) not only for Sturm-Liouville operators, but also for solving inverse problems for other more complicated classes of operators such as differential operators of arbitrary orders, differential operators with singularities and turning points, pencils of operators, integro-differential and integral operators and others. {$\bullet$} To reflect various applications of the inverse spectral problems in natural sciences and engineering. The book is organized as follows. In Chapter 1, Sturm-Liouville operators (1) on a finite interval are considered. In Sections 1.1-1.3 we study properties of spectral characteristics and eigenfunctions, and prove a completeness theorem and an expansion theorem. Sections 1.4- 1.8 are devoted to the inverse problem theory. We prove uniqueness theorems, give algorithms for the solution of the inverse problems considered, provide necessary and sufficient conditions for their solvability, and study stability of the solutions. We present several methods for solving inverse problems. The transformation operator method, in which the inverse problem is reduced to the solution of a linear integral equation, is described in Section 1.5. In Section 1.6 we present the method of spectral mappings, in which ideas of the contour integral method are used. The central role there is played by the so-called main equation of the inverse problem which is a linear equation in a corresponding Banach space. We give a derivation of the main equation, prove its unique solvability and provide explicit formulae for the solution of the inverse problem. At present time the contour integral method seems to be the most universal tool in the inverse problem theory for ordinary differential operators. It has a wide area for applications in various classes of inverse problems. In the method of standard models, which is described in Section 1.7, a sequence of model differential operators approximating the unknown operator are constructed. In Section 1.8 we provide the method for the local solution of the inverse problem from two spectra which is due to G. Borg [Bor1]. In this method, the inverse problem is reduced to a special nonlinear integral equation, which can be solved locally. Chapter 2 is devoted to Sturm-Liouville operators on the half-line. First we consider nonselfadjoint operators with integrable potentials. Using the contour integral method we study the inverse problem of recovering the Sturm-Liouville operator from its Weyl function. Then locally integrable complex-valued potentials are studied, and the inverse problem is solved by specifying the generalized Weyl function. In Chapter 3 Sturm-Liouville operators on the line are considered, and the inverse scattering problem is studied. In Chapter 4 we provide a number of applications of the inverse problem theory in natural sciences and engineering: we consider the solution of the Korteweg-de Vries equation on the line and on the half-line, solve the inverse problem of constructing parameters of a medium from incomplete spectral information, and study boundary value problems with aftereffect, inverse problems in elasticity theory and others. There exists an extensive literature devoted to inverse spectral problems. Instead of trying to give a complete list of all relevant contributions, we mention only monographs, survey articles and the most important papers, and refer to the references therein. In Section 1.9 we give a short review on literature on the inverse problem theory. The full text can be found as pdf in the internet (search for: Inverse Sturm--Liouville Problems and Their Applications)},
  file = {C:\Users\fbien.DESKTOP-6FMEAR7\Zotero\storage\4K8UKJ37\Freiling and Yurko - 2001 - Inverse Sturm–Liouville Problems and Their Applica.pdf}
}

@article{jensenNumericalMethodsInverse2018,
  title = {Numerical Methods for the Inverse Problem of Density Functional Theory},
  author = {Jensen, Daniel S. and Wasserman, Adam},
  year = {2018},
  journal = {International Journal of Quantum Chemistry},
  volume = {118},
  number = {1},
  pages = {e25425},
  issn = {1097-461X},
  doi = {10.1002/qua.25425},
  urldate = {2024-03-07},
  abstract = {The inverse problem of Kohn--Sham density functional theory (DFT) is often solved in an effort to benchmark and design approximate exchange-correlation potentials. The forward and inverse problems of DFT rely on the same equations but the numerical methods for solving each problem are substantially different. We examine both problems in this tutorial with a special emphasis on the algorithms and error analysis needed for solving the inverse problem. Two inversion methods based on partial differential equation constrained optimization and constrained variational ideas are introduced. We compare and contrast several different inversion methods applied to one-dimensional finite and periodic model systems.},
  copyright = {{\copyright} 2017 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {density functional theory,inverse problems,PDE-constrained optimization},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\MKSE2TQA\\Jensen and Wasserman - 2018 - Numerical methods for the inverse problem of densi.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\BQHYH4U6\\qua.html}
}

@misc{jinPhysicsInformedNeuralNetworks2022,
  title = {Physics-{{Informed Neural Networks}} for {{Quantum Eigenvalue Problems}}},
  author = {Jin, Henry and Mattheakis, Marios and Protopapas, Pavlos},
  year = {2022},
  month = feb,
  number = {arXiv:2203.00451},
  eprint = {2203.00451},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.00451},
  urldate = {2024-03-07},
  abstract = {Eigenvalue problems are critical to several fields of science and engineering. We expand on the method of using unsupervised neural networks for discovering eigenfunctions and eigenvalues for differential eigenvalue problems. The obtained solutions are given in an analytical and differentiable form that identically satisfies the desired boundary conditions. The network optimization is data-free and depends solely on the predictions of the neural network. We introduce two physics-informed loss functions. The first, called ortho-loss, motivates the network to discover pair-wise orthogonal eigenfunctions. The second loss term, called norm-loss, requests the discovery of normalized eigenfunctions and is used to avoid trivial solutions. We find that embedding even or odd symmetries to the neural network architecture further improves the convergence for relevant problems. Lastly, a patience condition can be used to automatically recognize eigenfunction solutions. This proposed unsupervised learning method is used to solve the finite well, multiple finite wells, and hydrogen atom eigenvalue quantum problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Quantum Physics},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\3LNSK5JG\\Jin et al. - 2022 - Physics-Informed Neural Networks for Quantum Eigen.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\2FH5ZHS3\\2203.html}
}

@misc{jinPhysicsInformedNeuralNetworks2022a,
  title = {Physics-{{Informed Neural Networks}} for {{Quantum Eigenvalue Problems}}},
  author = {Jin, Henry and Mattheakis, Marios and Protopapas, Pavlos},
  year = {2022},
  month = feb,
  number = {arXiv:2203.00451},
  eprint = {2203.00451},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.00451},
  urldate = {2024-03-07},
  abstract = {Eigenvalue problems are critical to several fields of science and engineering. We expand on the method of using unsupervised neural networks for discovering eigenfunctions and eigenvalues for differential eigenvalue problems. The obtained solutions are given in an analytical and differentiable form that identically satisfies the desired boundary conditions. The network optimization is data-free and depends solely on the predictions of the neural network. We introduce two physics-informed loss functions. The first, called ortho-loss, motivates the network to discover pair-wise orthogonal eigenfunctions. The second loss term, called norm-loss, requests the discovery of normalized eigenfunctions and is used to avoid trivial solutions. We find that embedding even or odd symmetries to the neural network architecture further improves the convergence for relevant problems. Lastly, a patience condition can be used to automatically recognize eigenfunction solutions. This proposed unsupervised learning method is used to solve the finite well, multiple finite wells, and hydrogen atom eigenvalue quantum problems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Quantum Physics},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\Y58NJ652\\Jin et al. - 2022 - Physics-Informed Neural Networks for Quantum Eigen.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\FXY6IUGF\\2203.html}
}

@misc{mcclennySelfAdaptivePhysicsInformedNeural2022,
  title = {Self-{{Adaptive Physics-Informed Neural Networks}} Using a {{Soft Attention Mechanism}}},
  author = {McClenny, Levi and {Braga-Neto}, Ulisses},
  year = {2022},
  month = apr,
  number = {arXiv:2009.04544},
  eprint = {2009.04544},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2009.04544},
  urldate = {2024-03-07},
  abstract = {Physics-Informed Neural Networks (PINNs) have emerged recently as a promising application of deep neural networks to the numerical solution of nonlinear partial differential equations (PDEs). However, it has been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of "stiff" PDEs. In this paper, we propose a fundamentally new way to train PINNs adaptively, where the adaptation weights are fully trainable and applied to each training point individually, so the neural network learns autonomously which regions of the solution are difficult and is forced to focus on them. The self-adaptation weights specify a soft multiplicative soft attention mask, which is reminiscent of similar mechanisms used in computer vision. The basic idea behind these SA-PINNs is to make the weights increase as the corresponding losses increase, which is accomplished by training the network to simultaneously minimize the losses and maximize the weights. We show how to build a continuous map of self-adaptive weights using Gaussian Process regression, which allows the use of stochastic gradient descent in problems where conventional gradient descent is not enough to produce accurate solutions. Finally, we derive the Neural Tangent Kernel matrix for SA-PINNs and use it to obtain a heuristic understanding of the effect of the self-adaptive weights on the dynamics of training in the limiting case of infinitely-wide PINNs, which suggests that SA-PINNs work by producing a smooth equalization of the eigenvalues of the NTK matrix corresponding to the different loss terms. In numerical experiments with several linear and nonlinear benchmark problems, the SA-PINN outperformed other state-of-the-art PINN algorithm in L2 error, while using a smaller number of training epochs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\GPNZMX8B\\McClenny and Braga-Neto - 2022 - Self-Adaptive Physics-Informed Neural Networks usi.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\2Q5GGD7M\\2009.html}
}

@article{mushtaqNumericalSolutionsQuantum2020,
  title = {Numerical {{Solutions}} of {{Quantum Mechanical Eigenvalue Problems}}},
  author = {Mushtaq, Asif and Noreen, Amna and Olaussen, K{\aa}re},
  year = {2020},
  month = sep,
  journal = {Frontiers in Physics},
  volume = {8},
  publisher = {Frontiers},
  issn = {2296-424X},
  doi = {10.3389/fphy.2020.00390},
  urldate = {2024-03-07},
  abstract = {A large class of problems in quantum physics involve solution of the time independent Schr{\"o}dinger equation in one or more space dimensions. These are boundary value problems, which in many cases only have solutions for specific (quantized) values of the total energy. In this article we describe a Python package that ``automagically'' transforms an analytically formulated Quantum Mechanical eigenvalue problem to a numerical form which can be handled by existing (or novel) numerical solvers. We illustrate some uses of this package. The problem is specified in terms of a small set of parameters and selectors (all provided with default values) that are easy to modify, and should be straightforward to interpret. From this the numerical details required by the solver is generated by the package, and the selected numerical solver is executed. In all cases the spatial continuum is replaced by a finite rectangular lattice. We compare common stensil discretizations of the Laplace operator with formulations involving Fast Fourier (and related trigonometric) Transforms. The numerical solutions are based on the NumPy and SciPy packages for Python 3, in particular routines from the {\textbackslash}btt\{scipy.linalg\}, {\textbackslash}btt\{scipy.sparse.linalg\}, and {\textbackslash}btt\{scipy.fftpack\} libraries. These, like most Python resources, are freely available for Linux, MacOS, and MSWindows. We demonstrate that some interesting problems, like the lowest eigenvalues of anharmonic oscillators, can be solved quite accurately in up to 3 space dimensions on a modern laptop --- with some patience in the 3-dimensional case. We demonstrate that a reduction in the lattice distance, for a fixed the spatial volume, does not necessarily lead to more accurate results: A smaller lattice length increases the spectral width of the lattice Laplace operator, which in turn leads to an enhanced amplification of the numerical noise generated by round-off errors.},
  langid = {english},
  keywords = {Eigenvalue problems,FFT (Fast Fourier Transform),keyword,Numpy Array,Python classes,quantum mechanics,Schrodinger equations,Sparse SciPy routines},
  file = {C:\Users\fbien.DESKTOP-6FMEAR7\Zotero\storage\RZ7ZQQWN\Mushtaq et al. - 2020 - Numerical Solutions of Quantum Mechanical Eigenval.pdf}
}

@misc{NeuralNetworksComputing,
  title = {Neural Networks for Computing Eigenvalues and Eigenvectors {\textbar} {{Biological Cybernetics}}},
  urldate = {2024-03-07},
  howpublished = {https://link.springer.com/article/10.1007/BF00201437},
  file = {C:\Users\fbien.DESKTOP-6FMEAR7\Zotero\storage\NTVLYXGE\BF00201437.html}
}

@article{schwabDeepNullSpace2019,
  title = {Deep {{Null Space Learning}} for {{Inverse Problems}}: {{Convergence Analysis}} and {{Rates}}},
  shorttitle = {Deep {{Null Space Learning}} for {{Inverse Problems}}},
  author = {Schwab, Johannes and Antholzer, Stephan and Haltmeier, Markus},
  year = {2019},
  month = feb,
  journal = {Inverse Problems},
  volume = {35},
  number = {2},
  eprint = {1806.06137},
  primaryclass = {math},
  pages = {025008},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/1361-6420/aaf14a},
  urldate = {2024-03-07},
  abstract = {Recently, deep learning based methods appeared as a new paradigm for solving inverse problems. These methods empirically show excellent performance but lack of theoretical justification; in particular, no results on the regularization properties are available. In particular, this is the case for two-step deep learning approaches, where a classical reconstruction method is applied to the data in a first step and a trained deep neural network is applied to improve results in a second step. In this paper, we close the gap between practice and theory for a new network structure in a two-step approach. For that purpose, we propose so called null space networks and introduce the concept of M-regularization. Combined with a standard regularization method as reconstruction layer, the proposed deep null space learning approach is shown to be a M-regularization method; convergence rates are also derived. The proposed null space network structure naturally preserves data consistency which is considered as key property of neural networks for solving inverse problems.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Numerical Analysis},
  file = {C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\VWMAP3W8\\Schwab et al. - 2019 - Deep Null Space Learning for Inverse Problems Con.pdf;C\:\\Users\\fbien.DESKTOP-6FMEAR7\\Zotero\\storage\\9QRD7BEM\\1806.html}
}

@misc{SpectralApproximationTransmission,
  title = {Spectral Approximation to a Transmission Eigenvalue Problem and Its Applications to an Inverse Problem - {{ScienceDirect}}},
  urldate = {2024-03-07},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S0898122115000978}
}
